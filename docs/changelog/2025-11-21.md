# 2025-11-21 변경 로그

## LangGraph 비동기/병렬 전환

- **상태 요약**: LLM 노드 호출과 FastAPI 스트리밍 루프를 전면적으로 비동기화해 모델 병렬 실행 기반을 마련
- **변경 내역**
  1. LangGraph 노드(`call_*`)를 `async def`로 전환하고 모든 LLM 호출에 `ainvoke` 우선, 미지원 모델은 executor로 감싸 비동기로 강제
  2. Send API 전용 `dispatch_llm_calls`를 도입해 `init_question`에서 5개 LLM 노드로 동시에 fan-out 하도록 구성
  3. `stream_graph`를 `app.astream` 기반 `async` 제너레이터로 바꿔 LangGraph 이벤트를 자연스럽게 비동기 스트림으로 노출
  4. `/api/ask` 라우터가 비동기 제너레이터로 이벤트를 송출하도록 업데이트하여 FastAPI가 asyncio 루프에서 바로 스트리밍하도록 개선
  5. FastAPI summary 응답에 모델 완료 순서/최초 완료 모델 정보를 추가하고 Streamlit UI가 이를 시각화
  6. Streamlit 호출부를 `httpx.stream()` 기반으로 교체해 HTTP/2 지원과 세분화된 예외 처리를 확보
  7. LangGraph 스트림/FastAPI/Streamlit 전 구간에 오류 이벤트 수집·요약 로직을 추가해 일부 모델 실패 시에도 서비스가 중단되지 않도록 개선
  8. `app/logger.py`에서 이모지 로그 포맷터를 도입하고 주요 모듈/스크립트에 적용하여 실행 상황을 일관되게 추적
  9. Streamlit UI를 `st.chat_input` 기반 챗봇 형태로 개편하고 메시지 로그/메타데이터 노출을 제거해 깔끔한 대화 흐름을 제공
- **다음 단계**
  1. Streamlit 측에서도 비동기 HTTP 클라이언트 실험 후 필요 시 교체
